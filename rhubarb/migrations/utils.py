import copy
import datetime
import logging
from collections import deque
from importlib.machinery import SourceFileLoader
from pathlib import Path
from typing import Iterator

from psycopg import AsyncConnection

from rhubarb.migrations.data import MigrationStateDatabase, Migration, AlterTable, MigrationOperation, DropColumn, \
    CreateColumn, RenameTable, DropTable, CreateTable, SetMeta

from rhubarb.errors import RhubarbException
from rhubarb.object_set import Registry


def find_diffs(
    old_state: MigrationStateDatabase, new_state: MigrationStateDatabase
) -> Iterator[MigrationOperation]:
    new_meta_kvs = {}
    new_meta_keys = new_state.meta.keys() - old_state.meta.keys()
    new_meta_kvs.update({k: new_state.meta[k] for k in new_meta_keys})
    new_meta_kvs.update(
        {k: v for k, v in old_state.meta.items() if new_state.meta[k] != v}
    )
    if new_meta_kvs:
        yield SetMeta(new_meta_kvs=new_meta_kvs)

    new_tables_keys = new_state.tables.keys() - old_state.tables.keys()
    for table_name in new_tables_keys:
        table_to_create = new_state.tables[table_name]
        yield CreateTable(
            schema=table_to_create.schema,
            name=table_to_create.name,
            class_name=table_to_create.class_name,
            primary_key=table_to_create.primary_key,
            constraints=table_to_create.constraints,
            indexes=table_to_create.indexes,
            columns=[
                CreateColumn(
                    name=c.name,
                    type=c.type,
                    python_name=c.python_name,
                    default=c.default,
                )
                for c in table_to_create.columns.values()
            ],
        )

    deleted_tables_keys = old_state.tables.keys() - new_state.tables.keys()
    for table_name in deleted_tables_keys:
        table_to_delete = old_state.tables[table_name]
        yield DropTable(
            schema=table_to_delete.schema,
            name=table_to_delete.name,
        )

    altered_keys = old_state.tables.keys() & new_state.tables.keys()
    for table_name in altered_keys:
        old_table = old_state.tables[table_name]
        new_table = new_state.tables[table_name]
        altered_statements = []

        if new_table.class_name != old_table.class_name:
            yield RenameTable(
                schema=old_table.schema,
                old_name=old_table.name,
                new_name=new_table.name,
                new_class_name=new_table.class_name,
            )

        new_columns_names = new_table.columns.keys() - old_table.columns.keys()
        for column_name in new_columns_names:
            column_to_create = new_table.columns[column_name]
            altered_statements.append(
                CreateColumn(
                    name=column_to_create.name,
                    type=column_to_create.type,
                    python_name=column_to_create.python_name,
                    default=column_to_create.default,
                )
            )

        deleted_column_names = old_table.columns.keys() - new_table.columns.keys()
        for column_name in deleted_column_names:
            columns_to_delete = old_table.columns[column_name]
            altered_statements.append(
                DropColumn(
                    name=columns_to_delete.name,
                )
            )

        if altered_statements:
            yield AlterTable(
                schema=new_table.schema,
                name=new_table.name,
                alter_operations=altered_statements,
            )


def run_operations(
    current_state: MigrationStateDatabase, ops: Iterator[MigrationOperation]
) -> MigrationStateDatabase:
    for op in ops:
        current_state = copy.deepcopy(current_state)
        current_state = op.forward(current_state)
    return current_state


MIGRATION_FILE_TEMPLATE = """# noqa\n# Generated by {program_name_version} on {timestamp:%Y%m%d-%H%M%S}

import rhubarb
from rhubarb as migrations
from rhubarb.migrations import *


def migrate():
    return migrations.Migration(
        id="{migration_id}",
        depends_on={depends_on},
        operations=[
{operations_joined}
        ]
    )
"""


def generate_migration_file(
    old_state, new_state, migration_heads: list[str], empty: bool
):
    timestamp = datetime.datetime.utcnow()
    operations = list(find_diffs(old_state=old_state, new_state=new_state))
    if not operations and not empty:
        logging.info("No Migrations to apply")
        return

    operations_joined = ",\n            ".join(op.__as_py__() for op in operations)
    migration_id = f"migration_{timestamp:%Y%m%d-%H%M%S}"
    depends_on = str(migration_heads)
    return f"{migration_id}.py", MIGRATION_FILE_TEMPLATE.format(
        program_name_version="rhubarb 0.1.0",
        timestamp=timestamp,
        operations_joined=operations_joined,
        migration_id=migration_id,
        depends_on=depends_on,
    )


def load_migrations(migration_dir: Path):
    seen_deps = set()
    migrations = {}
    for migration_file in migration_dir.glob("migration_*.py"):
        migration = SourceFileLoader(
            str(migration_dir.absolute()), str(migration_file)
        ).load_module()
        migration_obj: Migration = migration.migrate()
        seen_deps.update(migration_obj.depends_on)
        migrations[migration_obj.id] = migration_obj

    head_of_migrations = migrations.keys() - seen_deps
    return head_of_migrations, migrations


def current_migration_queue(head_of_migrations, migrations) -> Iterator[str]:
    migration_queue = deque(head_of_migrations)
    apply_queue = deque(head_of_migrations)
    while migration_queue:
        work_on = migration_queue.popleft()
        migration = migrations[work_on]
        migration_queue.extend(migration.depends_on)
        apply_queue.extend(migration.depends_on)
    return reversed(apply_queue)


def current_migration_state(head_of_migrations, migrations) -> MigrationStateDatabase:
    state = MigrationStateDatabase(tables={})
    if len(head_of_migrations) > 1:
        raise RhubarbException(
            f"There are two heads of the migration tree. make a new migration to set {head_of_migrations} as dependencies"
        )

    if not head_of_migrations:
        return state

    apply_queue = current_migration_queue(head_of_migrations, migrations)
    for migration in apply_queue:
        for operation in migrations[migration].operations:
            state = operation.forward(copy.deepcopy(state))

    return state


def load_migration(migration_dir: Path, migration_id):
    migration_file = f"migration_{migration_id}.py"
    migration = SourceFileLoader(
        str(migration_dir.absolute()), str(migration_file)
    ).load_module()
    return migration.migrate()


async def reset_db_and_fast_forward(conn: AsyncConnection, registry: Registry):
    current_state = MigrationStateDatabase()
    new_state = MigrationStateDatabase.from_registry(registry)
    await drop_tables_in_state(conn, new_state)
    for op in find_diffs(old_state=current_state, new_state=new_state):
        await op.run(current_state, conn)
        current_state = op.forward(current_state)


async def drop_tables_in_state(conn: AsyncConnection, state: MigrationStateDatabase):
    for _, table_name in state.tables.keys():
        logging.info(f"Dropping {table_name}")
        await conn.execute(f"DROP TABLE IF EXISTS {table_name}")
