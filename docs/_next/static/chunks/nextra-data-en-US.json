{"/advanced/default-where-clause":{"title":"Default Filter by User","data":{"":"For each model you can specify a custom __where__ clause that can take an optional Info. If you give an Info, you can then use the user from the request.\nimport rhubarb\nfrom rhubarb import table, column, references\nfrom rhubarb.errors import PermissionDenied\n\n\n# Filter model by user by default...\n@table\nclass SomeModel:\nname: str = column()\nuser_id = references(MyUserModel)\n\ndef __where__(self, info: Info):\nuser = info.context[\"request\"].user\nif not user.is_authenticated:\nraise PermissionDenied\nelif user.is_staff or user.is_superuser:\nreturn True\nreturn self.user_id == user.id\n\n\n@rhubarb.type\nclass Query:\n@rhubarb.field(graphql_type=list[SomeModel])\ndef my_field(self, info: Info):\n# To query SomeModel you must pass an info object now.\nreturn query(conn, SomeModel, info=info)"}},"/advanced/multi":{"title":"Multi","data":{"":"","making-multiple-selections-without-graphql#Making Multiple Selections without Graphql":"Using the Models through a GQL schema will automatically inline and combine relations. To get the same functionality, when manually using query outside of GQL, you will need to return a dataclass from select with all the data you want to return.\nimport dataclasses\n\n\n@dataclasses.dataclass\nclass R:\nauthor: Author\nbook: Book\n\n\n# Query author and book at the same time.\nq = query(conn, Book).select(lambda book: R(book=book, author=book.author()))\nresult: list[R] = await q.as_list()\nDataclasses are used instead of Tuples because there is no Tuple type in GQL."}},"/advanced/field-permissions":{"title":"Column and Field Permission","data":{"":"You can automatically raise an error if a usr tries to query a field they shouldn't using Strawberry Permission Classes.\nfrom rhubarb import column\nfrom rhubarb.permission_classes import IsAuthenticated, IsStaff, IsSuperUser\n\n@table\nclass MyModel:\ntax_id: str = column(permission_classes=[IsStaff])\n\n\n@field(permission_classes=[IsAuthenticated])\ndef must_be_logged_in(...):\npass\n\n\n@field(permission_classes=[IsStaff])\ndef must_be_staff(...):\npass\n\n\n@field(permission_classes=[IsSuperUser])\ndef must_be_superuser(...):\npass"}},"/advanced/sql-functions":{"title":"SQL Functions","data":{"":"In rhubarb.functions you can find many Postgres functions and aggregations already defined.\nPython\tPostgres\tNotes\tfunc\t\tuse a custom Postgres Function\tsum_agg\tSUM\tNeeds __group_by__\tcount_agg\tCOUNT\tNeeds __group_by__\tavg_agg\tAVG\tNeeds __group_by__\tmax_agg\tMAX\tNeeds __group_by__\tmin_agg\tMIN\tNeeds __group_by__\tstring_agg\tSTRING_AGG\tNeeds __group_by__\tarray_agg\tARRAY_AGG\tNeeds __group_by__\tjson_agg\tJSONB_AGG\tNeeds __group_by__\tconcat\tCONCAT\t\tcoalesce\tCOALESCE\t\tis_null\t<val>  IS NULL\t\tis_not_null\t<val> IS NOT NULL\t\tcase\tCASE\tcase((<cond>, <val>), (<cond2>, <val>), default=<val>)\tval\t\tPython value to pass to SQL (safe)\traw\t\tInterpolate string into SQL query without escaping (unsafe)"}},"/auth/impersonate":{"title":"Impersonating other Users","data":{"":"When using production, it can be useful to appear logged in as one of your customers.","using#Using":"The impersonate functions allow superusers to impersonate non-superusers. In order for the impersonate function to work, the superuser must have a current session on the request.\nfrom rhubarb.pkg.users.impersonate import (\nimpersonate,\nstop_impersonating,\n)\n\n\nawait impersonate(user, info.context[\"request\"])\n\nawait stop_impersonating(conn, info.context[\"request\"])","auditing#Auditing":"Impersonating a user will alter AuditEvent entries by adding an impersonator_id to the event. This is the ID of the superuser who is impersonating that user."}},"/contrib/arq-tasks":{"title":"Tasks With Arq","data":{"":"Arq is a TaskQueue based on Redis and Supports Asyncio and is integrated into Rhubarb.Rhubarb is a light wrapper around arq so read the documentation there to understand more about tasks.","creating-a-task#Creating a Task":"Create and register a task with the @task decorator.\nfrom rhubarb.pkg.arq.worker import task\n\n\n@task\nasync def my_task(ctx, some_param: int = 0):\nreturn 10 + some_param\nNow you can enqueue a task like so:\njob = await my_task.enqueue_job(some_param=1)\nres = await job.result()","running-a-worker#Running a worker":"A worker is run using the arq command line program. Specify the Rhubarb settings to load all tasks with the @task decorator.\npoetry run arq rhubarb.pkg.arq.worker.WorkerSettings","config#Config":"Use ARQ_TASK_MODULES to define a comma seperated list of modules (or one module that imports the other modules) of where all your tasks live.Since the @task decorate is lazy and only registers tasks if their module is imported, an ARQ worker won't run without ARQ_TASK_MODULES configured.\n@dataclasses.dataclass(frozen=True)\nclass ArqConfig:\ntask_modules: list[str] = dataclasses.field(default_factory=lambda: list_env(\"ARQ_TASK_MODULES\", []))\nredis: RedisConfig = dataclasses.field(default_factory=RedisConfig)"}},"/auth/using":{"title":"User Models and Authentication","data":{"":"Rhubarb comes with builtin User models and helper methods to make it easy to secure and organize your app for your end users.","setup#Setup":"By default you must define your own user model that extends the User superclass and link the user registry to your migrations.\nfrom rhubarb import DEFAULT_REGISTRY, table, column\nfrom rhubarb.pkg.users.models import User, user_registry\n\nDEFAULT_REGISTRY.link(user_registry)\n\n\n# Add your own user.\n@table\nclass MyUser(User):\nawesome_custom_field: int = column()\nUpdate your app's config to reflect the new user model, this will allow auditing and other plugins to make the correct references.\nconfig = Config(\nusers=UserConfig(\nuser_model=MyUser\n)\n)\nIn your HTTP Server you will have to add the Session and Authentication Middlewares\napp = Starlette(\nmiddleware=[\nMiddleware(SessionMiddleware),\nMiddleware(SessionAuthenticationMiddleware),\n],\nroutes=[Route(\"/graphql/\", GraphQL(schema))],\n)","logging-in#Logging In":"Force a login without checking password.\nuser = await get_user(conn, user_id)\nawait login(conn, user, info.context[\"request\"])\nCheck a user's password and log them in if it matches. This is rate limited by IP.\nawait try_login_with_pw(conn, user_id, password, info.context[\"request\"])","logging-out#Logging Out":"await logout(info.context[\"request\"])","checking-logged-in-users#Checking Logged-In Users":"After logging in, you can access the user from the request in Info's context.\n@rhubarb.type\nclass Query:\n@rhubarb.field\ndef current_user(self, info: Info) -> MyUser | None:\nif info.context[\"request\"].user.is_authenticated:\nreturn info.context[\"request\"].user\nreturn None","complete#Complete":"Here is an example putting git all together\nimport uuid\n\nimport rhubarb\nfrom rhubarb import Schema, Registry, table, get_conn\nfrom rhubarb.config import Config\nfrom rhubarb.pkg.users.models import User, user_registry, get_user\nfrom rhubarb.pkg.users.backends import login\nfrom rhubarb.pkg.users.config import UserConfig\nfrom rhubarb.pkg.users.middleware import SessionAuthenticationMiddleware\nfrom rhubarb.pkg.sessions.middleware import SessionMiddleware\nfrom rhubarb.pkg.starlette.applications import Starlette, GraphQL\n\nfrom strawberry.types import Info\nfrom starlette.routing import Route\nfrom starlette.middleware import Middleware\n\n\nmigrations_registry = Registry()\n# Link the user registry for supporting models.\nmigrations_registry.link(user_registry)\n\n\n# Add your own user.\n@table(registry=migrations_registry)\nclass MyUser(User):\npass\n\n\n@table(registry=migrations_registry)\nclass CustomModel:\npass\n\n\n\nconfig = Config(\nregistry=migrations_registry,\nusers=UserConfig(\nuser_model=MyUser\n)\n)\n\n\n@rhubarb.type\nclass Query:\n@rhubarb.field\ndef current_user(self, info: Info) -> MyUser | None:\nif info.context[\"request\"].user.is_authenticated:\nreturn info.context[\"request\"].user\nreturn None\n\n\n@rhubarb.type\nclass Mutation:\n@rhubarb.mutation\nasync def login(self, user_id: uuid.UUID, info: Info) -> MyUser:\nconn = get_conn(info)\nuser = await get_user(conn, user_id)\nreturn await login(conn, user, info.context[\"request\"])\n\n\nschema = Schema(\nquery=Query,\nmutation=Mutation,\n)\n\napp = Starlette(\nmiddleware=[\nMiddleware(SessionMiddleware),\nMiddleware(SessionAuthenticationMiddleware),\n],\nroutes=[Route(\"/graphql/\", GraphQL(schema, debug=True))],\n)"}},"/contrib/auditing":{"title":"Auditing","data":{"":"Rhubarb comes with built-in Auditing extension that can record all queries, subscriptions, and mutations.By default, the auditing extension will use a new connection to the database different from the current executing connection of the schema. This is to prevent Transaction rollbacks from deleting written audit events. It also allows you to specify an alternative auditing database (like TimeseriesDB) to silo your events.The default configuration only logs mutations. This is configurable with AuditConfig.\nfrom rhubarb import Schema\nfrom rhubarb.pkg.audit.extensions import AuditingExtension\n\n\nschema = Schema(\nquery=...,\nmutation=...,\nextensions=[\nAuditingExtension,\n]\n)","builtin-events#Builtin Events":"Extra events are recorded for login, logout, impersonate, stop_impersonating separately from the GQL mutation when auditing is in (if it is in one).","custom-events#Custom Events":"You an save custom Audit events with rhubarb.pkg.audit.models.log_event\nawait log_event(event_name=\"my_custom_event\", variables={\"wow\": 1})\n\n\n# Passing request will fill in the current user, IP, etc from the request object.\nawait log_event(request, event_name=\"my_custom_event\", variables={\"wow\": 1})","config#Config":"By default, audit will use the same DB configuration as your App. You can configure the audit database by specifying an enviornment variable.PG_AUDIT_URI - Connection String that describes a Postgres connection (e.g. postgres://USER:PASSWORD@HOST:PORT/DATABASE)\n@dataclasses.dataclass(frozen=True)\nclass AuditConfig:\naudit_mutations: bool = True\naudit_queries: bool = False\naudit_subscriptions: bool = False\nreuse_conn: bool = False\npostgres: PostgresConfig = dataclasses.field(\ndefault_factory=lambda: load_postgres_config(\"PG_AUDIT_URI\")\n)"}},"/contrib/email":{"title":"Emails","data":{"":"Rhubarb is configured to send standard Python Email's using aiosmtplib. See this\nfrom rhubarb.pkg.email.send import send\nfrom email.message import EmailMessage\n\nmsg = EmailMessage()\nmsg['Subject'] = \"My Awesome Email\"\nmsg['From'] = \"from_email@example.com\"\nmsg['To'] = ', '.join([\"to@example.com\", \"other@example.com\"])\nmsg.set_content(\"Yo.\")\n\nawait send(msg)","config#Config":"@dataclasses.dataclass(frozen=True)\nclass EmailConfig:\nhostname: Optional[str] = str_env(\"SMTP_HOSTNAME\")\nport: Optional[int] = int_env(\"SMTP_PORT\")\nsender: Optional[str] = str_env(\"SMTP_DEFAULT_SENDER\")\nusername: Optional[str] = str_env(\"SMTP_USERNAME\")\npassword: Optional[str] = str_env(\"SMTP_PASSWORD\")\ntimeout: Optional[float] = float_env(\"SMTP_TIMEOUT\", DEFAULT_TIMEOUT)\nuse_tls: bool = bool_env(\"SMTP_USE_TLS\", False)\nstart_tls: Optional[bool] = bool_env(\"SMTP_START_TLS\")\nvalidate_certs: bool = bool_env(\"SMTP_VALIDATE_CERTS\")\nclient_cert: Optional[str] = str_env(\"SMTP_CLIENT_CERT\")\nclient_key: Optional[str] = str_env(\"SMTP_CLIENT_KEY\")"}},"/contrib/redis":{"title":"Redis","data":{"":"Rhubarb has built in integrations with Redis for caching, ratelimiting and pubsub.","general-usage#General usage":"You can get a redis connection from the currently configured pool with from rhubarb.pkg.redis.connection import connection and use it like normal.\nfrom rhubarb.pkg.redis.connection import connection\n\nasync def use_redis():\nasync with connection() as r:\nawait r.set(\"some_key\", \"some_value\")\nreturn await r.get(\"some_key\")","caching#Caching":"Rhubarb has builtin support for caching function results in Redis.\nfrom rhubarb.pkg.redis.cache import cache, local_cache, local_only_cache, clear_cache\n\nimport aiohttp\n\n# Cache a function in Redis for a minute\n@cache(ttl_seconds=60)\nasync def cached_fn():\nresp = await aiohttp.get(\"http://example.com\")\nreturn resp.json()\n\n# Cache a function locally and in Redis. On Read, prioritize local memory.\n@local_cache(ttl_seconds=60)\nasync def cached_fn():\nresp = await aiohttp.get(\"http://example.com\")\nreturn resp.json()\n\n\n# Cache a function locally only.\n@local_only_cache(ttl_seconds=60)\nasync def local_only_cache():\nresp = await aiohttp.get(\"http://example.com\")\nreturn resp.json()","clear-the-cache#Clear the cache":"Clear a function's cache by passing the decorated function into clear_cache\nawait clear_cache(cached_fn)","a-note-about-local-caching#A note about Local Caching":"Be careful, clearing cache with local if your app is distributed. Clearing a local cache will only clear the local cache on the current machine. Therefore local_cache and local_only_cache should only be used with data that doesn't get stale (i.e. immutable data)","rate-limiting#Rate limiting":"Rhubarb has built-in a rate limit context manager and decorator. It is synchronized by Redis so can be used in distributed apps to secure parts of the code from bad actors.\nfrom starlette.requests import Request\nfrom rhubarb.pkg.redis.rate_limit import rate_limit\n\n\n# Rate limit by IP. Once a minute.\nasync def once_a_minute(request: Request):\nwith rate_limit(key=f\"my_action-{request.client.host}\", max_times=1, ttl_seconds=60):\nreturn await some_other_function()\n\n\n# Rate limit as a decorator (this ratelimit would use the same key for all users).\n@rate_limit(key=f\"my_action\", max_times=1, ttl_seconds=60)\nasync def once_a_minute():\nreturn await some_other_function()","config#Config":"@dataclasses.dataclass(frozen=True)\nclass RedisConfig:\nhost: str = str_env(\"REDIS_HOST\", \"127.0.0.1\")\nport: int = int_env(\"REDIS_PORT\", 6379)\nusername: Optional[str] = str_env(\"REDIS_USERNAME\", None)\npassword: Optional[str] = str_env(\"REDIS_PASSWORD\", None)\ndb: int = int_env(\"REDIS_DB\", 0)\nmax_connections: Optional[int] = int_env(\"REDIS_MAX_CONNECTIONS\")"}},"/contrib/starlette":{"title":"Starlette","data":{"":""}},"/contrib/webauthn":{"title":"Webauthn","data":{"":""}},"/fields/aggregations":{"title":"Aggregations","data":{"":"Aggregations are done by making a virtual table by setting registry to None and then specifying a __group_by__.Once a __group_by__ is set on a table, all methods and virtual columns have to be aggregate functions or included in the group by.Rhubarb will make a subquery and join to do the groupby in order to avoid mixing groupby in your parent query.\nfrom rhubarb import  ModelSelector, BaseModel, column, table, relation, virtual_column\nfrom rhubarb.functions import sum_agg, avg_agg\n\n\n@table\nclass Pet(BaseModel):\nname: str = column()\nowner_id: str = column()\nweight_lbs: float = column()\n\n\n@table(skip_registry=True)\nclass PetByOwner(Pet):\n@virtual_column\ndef avg_weight(self: ModelSelector) -> float:\nreturn avg_agg(self, self.weight_lbs)\n\n@virtual_column\ndef weight_of_all_lets(self: ModelSelector) -> float:\nreturn sum_agg(self, self.weight_lbs)\n\ndef __group_by__(self):\nreturn self.owner_id\n\n\n@table\nclass Person(BaseModel):\nname: str = column()\n\n# Specify relation list of objects. Optimization fence.\n@relation(graphql_type=list[Pet])\ndef pets(self, pet: Pet):\nreturn self.id == pet.owner_id\n\n@relation\ndef pet_stats(self, stats: PetByOwner):\nreturn self.id == stats.owner_id\n\n@virtual_column\ndef avg_pet_weight(self) -> float:\nreturn self.pet_stats().avg_weight"}},"/fields/mutations":{"title":"Mutations","data":{"":"Insert, Update, Delete are also optimized for GQL and can be used in Mutations.\nimport uuid\nfrom rhubarb import Schema, ModelSelector, ModelUpdater, RhubarbExtension, type, \\\nget_conn, mutation, update, query, save\nfrom rhubarb.functions import concat\nfrom strawberry.types import Info\n\n\n@type\nclass Mutation:\n@mutation\ndef update_person(self, info: Info, person_id: uuid.UUID, new_name: str) -> Person:\ndef do(person: ModelUpdater[Person]):\n# With Update expressions, we can use computations and reference sql fields and joins.\nperson.title = concat(\nnew_name, \"(Old Name: \", person.title, \")\"\n)\n\ndef where(person: ModelSelector[Person]):\nreturn person.id == person_id\n\n# Even though this mutation is not async, we are returning an UpdateSet which will\n# be executed by Rhubarb async middleware.\nreturn update(get_conn(info), Person, do, where, info=info, one=True)\n\n@mutation\nasync def update_name(\nself, info: Info, person_id: uuid.UUID, new_name: str\n) -> Person:\nconn = get_conn(info)\n# Or avoid the optimization extension and just use await statements.\nobj = await by_pk(conn, Person, person_id).one()\nobj.title = new_name\nreturn await save(conn, obj, info=info)\n\n\nschema = Schema(\nquery=Query,\nmutation=Mutation\n)"}},"/fields/python-based-fields":{"title":"Computations executed in Python","data":{"":"Sometimes you may not want to have all your computations be in SQL. If you want a table method to execute in Python, use the python_field.python_field takes a function which you use to list your dependencies for the computation. This allows you to specify any other SQL computation or column to feed into your function.","example#Example":"Here, we pass in a lambda which takes a ModelSelector that we can use to specify what SQL fields we will need to do the computation in Python.Note that self in a python_field is still a ModelSelector and not the Python object.\n@python_field(lambda x: [x.first_name, x.last_name])\ndef full_name_python(self, first_name: str, last_name: str) -> str:\nreturn f\"{first_name} {last_name}\"\nHere is a bigger example:\nimport uuid\nfrom rhubarb import BaseModel, column, table, relation, python_field, virtual_column\nfrom rhubarb.functions import concat\n\n\n@table\nclass Address(BaseModel):\ncity: str = column()\nstate: str = column()\nperson_id: uuid.UUID = column()\n\n\n@table\nclass Person(BaseModel):\nfirst_name: str = column()\nlast_name: str = column()\nfavorite_pokemon: int = column()\n\n@relation\ndef address(self, address: Address):\nreturn self.id == address.person_id\n\n# Executed in SQL so need to use special SQL function.\n@virtual_column\ndef full_name_sql(self) -> str:\nreturn concat(self.first_name, \" \", self.last_name)\n\n# Executed in Python, you have to list the SQL dependencies.\n@python_field(lambda x: [x.first_name, x.last_name])\ndef full_name_python(self, first_name: str, last_name: str) -> str:\nreturn f\"{first_name} {last_name}\"\n\n# Can use kwargs and async functions...\n@python_field(lambda x: {\"fn\": x.first_name, \"pokemon_id\": x.favorite_pokemon})\nasync def api_backed_python_field(self, fn: str, pokemon_id: int) -> str:\n# In the real world, probably would cache this HTTP Call or something.\nasync with aiohttp.ClientSession() as session:\npokemon_url = f'https://pokeapi.co/api/v2/pokemon/{pokemon_id}/'\nasync with session.get(pokemon_url) as resp:\npokemon = await resp.json()\npokemon_name = pokemon[\"name\"]\nreturn f\"{fn}'s Favorite Pokemon is pokemon {pokemon_name}\"\n\n# Can use relations and other virtual columns...\n@python_field(lambda x: {\"sql_full_name\": x.full_name_sql(), \"address\": x.address()})\ndef full_name_with_relation_python(self, sql_full_name: str, address: Address) -> str:\nreturn f\"{sql_full_name} from {address.city} {address.state}\""}},"/fields/relations":{"title":"Relations","data":{"":"Rhubarb will follow child selections and inline as many queries for relation data as possible. This means that most relations that return 1 or 0 objects can be inlined in the same Query as their parent object.","specify-a-sql-reference-constraint#Specify a SQL Reference Constraint":"When defining your model, specify a reference to another model's table.\nowner_id: uuid.UUID = references(MyModel)\nYou can also do it lazily if the Model is defined after it.\nowner_id: uuid.UUID = references(lambda: MyModel)","relation-with-one-or-none-objects#Relation with One or None objects":"By default a relation field computes one or None related objects. you create a relation field by decorating a method that returns a boolean selector.\n@table\nclass Pet:\nowner_id: uuid.UUID = references(Person)\n\n@relation\ndef owner(self: ModelSelector[Pet], owner: Person):\nreturn self.owner_id == owner.id","relationships-with-many-objects#Relationships with Many Objects":"If you have a parent with many children, you can return a list of children by specifying that you want to return a list using graphql_type like so @relation(graphql_type=list[Pet]).Because Rhubarb Aggressively inlines all possible fields into a SQL Query, if you return a list from a Relation, there is an optimization fence in which Rhubarb will no longer try to inline the relation. Rhubarb will instead start a new tree and start inlining as many children as possible. This is to avoid exploding cartesian products.\nimport uuid\nfrom rhubarb import  BaseModel, column, table, relation, references\n\n\n@table\nclass Pet(BaseModel):\nname: str = column()\nowner_id: uuid.UUID = references(lambda: Person)\n\n# Default relation returns a single object\n@relation\ndef owner(self, owner: \"Person\"):\nreturn self.owner_id == owner.id\n\n\n@table\nclass Person(BaseModel):\nname: str = column()\n\n# Specify relation list of objects. Optimization fence.\n@relation(graphql_type=list[Pet])\ndef pets(self, pet: Pet):\nreturn self.id == pet.owner_id"}},"/fields/virtual_columns":{"title":"Virtual Columns","data":{"":"Rhubarb tables are different from standard Python objects. methods decorated with virtual_column and field are not executed in Python. These methods are pushed down and transformed into SQL to be executed on the Postgres Server.\nfrom rhubarb import  BaseModel, ModelSelector, column, table, virtual_column\nfrom rhubarb.functions import concat, case, val\n\n\n@table\nclass Person(BaseModel):\nfirst_name: str = column()\nlast_name: str = column()\nfavorite_number: int = column()\nscore: int = column()\n\n@virtual_column\ndef full_name(self: ModelSelector) -> str:\nreturn concat(self.first_name, self.last_name)\n\n@virtual_column\ndef favorite_number_is_42(self: ModelSelector) -> bool:\nreturn self.favorite_number == 42\n\n@virtual_column\ndef case_computation(self: ModelSelector) -> str:\nreturn case(\n(self.score == 0, val(\"Bad\")),\n(self.score < 5, val(\"Poor\")),\n(self.score < 7, val(\"Good\")),\ndefault=val(\"Excellent\")\n)"}},"/getting_started/basic-usage":{"title":"Rhubarb Basics","data":{"":"Rhubarb is built to make it easy to query data in a Pythonic way. It does this through Python objects that represent SQL operations.","tables#Tables":"Define tables using the @table decorator and column fields. virtual_column are computations that get converted into SQL and run on Postgres.\nfrom rhubarb import BaseModel, table, column, virtual_column\nfrom rhubarb.functions import concat\n\n\n@table\nclass MyModel(BaseModel):\nfirst_name: str = column()\nlast_name: str = column()\n\n@virtual_column\ndef full_name(self):\nreturn concat(self.first_name, \" \", self.last_name)","schema#Schema":"Expose your Tables in a GQL Schema by creating a Query.\nimport rhubarb\nfrom rhubarb import Schema, query, get_conn\n\n\n@rhubarb.type\nclass Query:\n@rhubarb.field(graphql_type=list[MyModel])\ndef all_my_models(self, info: Info):\nreturn query(get_conn(info), MyModel, info)\n\n\nschema = Schema(\nquery=Query\n)","modelselectors#ModelSelectors":"Rhubarb is built around the ModelSelector which wraps your type and converts python operations into SQL functions. Only fields are accessible from this ModelSelector. Extra attributes or functions that aren't fields will not be able to be accessed.\ndef where_fn(s: ModelSelector[MyModel]):\nreturn (s.first_name == \"bob\") and (s.last_name == \"jones\")\n\n\ndef select_fn(s: ModelSelector[MyModel]):\nreturn s.email\n\n\nquery(MyModel, conn).where(where_fn).select(select_fn)","modelselectors-and-self#ModelSelectors and self":"When you create a virtual_column, field or relation the self argument to the function is not the dataclass type, but actually a ModelSelector type.\n@table\nclass MyModel:\n@virtual_column\ndef int_is_big(self: ModelSelector[MyModel]) -> bool:\nreturn self.example_int_col > 100","modelsetters#ModelSetters":"Like a ModelSelector, the update function has a ModelSetter which accumulates the changes you which to make in an UPDATE:\ndef set_fn(s: ModelSelector[MyModel]):\ns.email = \"new@example.com\"\n\n\nquery(MyModel, conn).update(set_fn)","using-kwargs-instead#Using Kwargs Instead":"Rhubarb exposes shortcut functions for you to use **kwargs to filter and update data also.\nquery(MyModel, conn).kw_where(first_name=\"bob\", last_name=\"jones\").kw_update(email=\"new@example.com\")"}},"/getting_started/config":{"title":"App Configuration","data":{"":"Rhubarb is built to be configured with environment variables. They are extremely convenient and have a lot of benefits for when you are deploying the same code to many places that may have different DB configs, etc.","basic-environment-vars#Basic Environment Vars":"The core Environment Vars that you will likely change are:\nEnv\tDescription\tSECRET_KEY\tSecret Key used for HTTP Cookies\tORIGINS\tA comma seprated list of domains with protocol to accept for CSRF, CORS, WebAuthN, etc. (https://myapp.com,https://sub.myapp.com)\tPG_URI\tConnection String that describes a Postgres connection (postgres://USER:PASSWORD@HOST:PORT/DATABASE)\tREDIS_URI\tConnection String that describes a Redis connection (redis://USER:PASSWORD@HOST:PORT/DATABASE)","config#Config":"Rhubarb's configuration is centered around frozen dataclasses that are loaded when your program starts. Once loaded, you can access the config and their related resources using the config() method.\n@dataclasses.dataclass(frozen=True)\nclass Config:\nmigration_directory: Path = Path(\"./migrations\")\nregistry: Registry = dataclasses.field(default_factory=lambda: DEFAULT_REGISTRY)\ncors: CorsConfig = dataclasses.field(default_factory=CorsConfig)\npostgres: PostgresConfig = dataclasses.field(default_factory=load_postgres_config)\nredis: RedisConfig = dataclasses.field(default_factory=load_redis_config)\nusers: UserConfig = dataclasses.field(default_factory=UserConfig)\naudit: AuditConfig = dataclasses.field(default_factory=AuditConfig)\nsessions: SessionConfig = dataclasses.field(default_factory=SessionConfig)\nwebauthn: WebAuthnConfig = dataclasses.field(default_factory=WebAuthnConfig)\narq: ArqConfig = dataclasses.field(default_factory=ArqConfig)\nlocalcache: Cache = dataclasses.field(\ndefault_factory=lambda: TTLCache(maxsize=1024, ttl=600)\n)\nemail: EmailConfig = dataclasses.field(default_factory=lambda: EmailConfig())\nFor each part of the app, a subconfig is used that is used to load the data from the environment vars. For instance here is the Postgres configuration.\n@dataclasses.dataclass(frozen=True)\nclass PostgresConfig:\nhost: str = str_env(\"PG_HOST\", \"localhost\")\nport: int = int_env(\"PG_PORT\", 5432)\nuser: str = str_env(\"PG_USER\", \"postgres\")\npassword: str = str_env(\"PG_PASSWORD\", \"postgres\")\ndbname: str = str_env(\"PG_DBNAME\", \"postgres\")\nmin_size: int = int_env(\"PG_POOL_MIN_SIZE\", 4)\nmax_size: int | None = int_env(\"PG_POOL_MAX_SIZE\")\nThe configs in general are setup to load their values from the environment.When db configurations (Redis, Postgres) are used in multiple configs, the config itself is hashed and a single Pool instance per config hash is then shared between separate configs with the same values.","custom-configs#Custom Configs":"You can add your own fields to the Rhubarb config by subclassing. Your module containing a config should contain the minimum imports needed to avoid circular imports.\n@dataclasses.dataclass(frozen=True)\nclass CustomConfig(Config):\nawesome_setting: str = str_env(\"AWESOME_ENV_VAR\", \"woah\")\n\n\n# you can instantiate your config with a callable if you want more flexibility\ndef config_fn():\nreturn CustomConfig(\nregistry=my_custom_registry,\naudit=AuditConfig(\naudit_queries=True,\naudit_subscriptions=True\n)\n)\nTell Rhubarb where to find your custom config. It can either be the class or the object. If it is a callable or class, it will be initialized into an object on import.\nRHUBARB_CONFIG=\"import_path.to_my.custom_config.CustomConfig\" python -m rhubarb.pkg.starlette.server\nAccess it through config() (trying to manually access your config directly through an import will probably cause circular imports)\nfrom rhubarb.config import config\n\ndef my_function() -> str:\nconf: CustomConfig = config()\nreturn conf.awesome_setting\nYou can only use config() lazily in a function, never as a top level import.","init_rhubarb#init_rhubarb()":"If you are manually running scripts outside of rhubarbs entrypoints for HTTP servers, tasks, etc, you will need to call init_rhubarb exactly once for each process. This is done for you automatically if you use commands supplied by Rhubarb."}},"/getting_started/installation":{"title":"Install","data":{"":"Poetry is the preferred way to manage a Rhubarb App.\npoetry new rhubarb-demo\ncd rhubarb-demo\npoetry add rhubarb-graphql\nCreate a minimal app at rhubarb-demo/app.py\nimport rhubarb\nfrom rhubarb import Schema, BaseModel, table, column, query, get_conn\nfrom rhubarb.pkg.starlette.applications import Starlette, GraphQL\nfrom starlette.routing import Route\nfrom strawberry.types import Info\n\n\n@table\nclass MyModel(BaseModel):\nfirst_name: str = column()\nlast_name: str = column()\n\n\n@rhubarb.type\nclass Query:\n@rhubarb.field(graphql_type=list[MyModel])\ndef all_my_models(self, info: Info):\nreturn query(get_conn(info), MyModel, info)\n\n\nschema = Schema(\nquery=Query\n)\n\napp = Starlette(\nroutes=[Route(\"/graphql/\", GraphQL(schema, debug=True))],\n)\nRun a docker compose file if necessary for Redis and Postgres.\nservices:\npostgres:\nimage: postgres:alpine\nenvironment:\nPOSTGRES_DB: postgres\nPOSTGRES_PASSWORD: postgres\nPOSTGRES_USER: postgres\nports:\n- 5435:5432\nredis:\nimage: redis:latest\nports:\n- 6379:6379\nCreate and apply migrations for your app.\npoetry run python -m rhubarb.migrations.cmd.make\npoetry run python -m rhubarb.migrations.cmd.apply\nRun your app:\npoetry run uvicorn rhubarb_demo.app:app\nNavigate to http://localhost:8000/graphql/ to use the GraphiQL tool to interact with your API."}},"/getting_started/optimizations":{"title":"Optimizations","data":{"":"The RhubarbExtension will look at returned ObjectSets, UpdateSets, DeleteSets and InsertSets and optimize them based on the current GQL query. If you execute the objectset into a list or object, this optmization cannot occur.If you are in doubt, try to write fields as non-async functions which will prevent a DB hit outside of the Extension.\n@field\nasync def some_field(...):\n# return an list, not optimized by extension.\nreturn await query(conn, Model).as_list()\n\n\n@field\nasync def some_field(...):\n# return an object, not optimized by extension.\nreturn await query(conn, Model).one()\n\n\n@field\ndef some_field(...):\n# return an objectset, optimized by extension\nreturn query(conn, Model)\n\n\n@field\ndef some_field(...):\n# return an objectset that returns 1 object, optimized by extension\nreturn query(conn, Model, one=True)\n\n\n@mutation\nasync def update_name(...):\n...\n# This would execute the function and select all field, children queries not optimized.\nreturn await save(conn, obj).execute()\n\n\n@mutation\nasync def update_name(...):\n...\n# This returns an UpdateSet to Extension, Extension determine what fields to select.\nreturn save(conn, obj)"}},"/getting_started/querying-data":{"title":"Querying Data","data":{"":"You can either use a Strawberry Schema or use the Model directly.","using-gql-in-python-as-client#Using GQL in Python as Client":"We can use our schema to make queries and Rhubarb will optimize them for you.\nfrom rhubarb.pkg.postgres.connection import connection\n\nasync with connection() as conn:\nres = await schema.execute(\n\"\"\"\nquery {\nall_people {\nname\nint_is_big\na_bool_column\nother_table {\nid\ninfo\n}\n}\n}\n\"\"\",\ncontext_value={\"conn\": conn}\n)","without-gql#Without GQL":"You can also make queries  like a normal ORM for use in general Python apps and tasks.\nfrom rhubarb import query, Desc\nfrom rhubarb.pkg.postgres.connection import connection\n\nasync with connection() as conn:\nbool_list: list[bool] = await query(conn, Person).select(lambda x: x.int_is_big()).as_list()","cheat-sheet#Cheat Sheet":"Below is a quick reference for building sets of data.","objectset--updateset--deleteset#ObjectSet / UpdateSet / DeleteSet":"ObjectSet, UpdateSet, and DeleteSet are lazily built up. An ObjectSet can be converted to an UpdateSet or DeleteSet by calling .update or .delete.\nimport datetime\nfrom rhubarb.crud import query, by_kw, by_pk, save, insert_objs, reload\n\n# Use keywords\nquery(conn, Person).kw_where(username=\"my_username\")\nby_kw(conn, Person, username=\"my_username\")\nby_kw(conn, Person, created__lt=datetime.datetime.now() - datetime.timedelta(1))\nby_kw(conn, Person, created__lte=datetime.datetime.now() - datetime.timedelta(1))\nby_kw(conn, Person, created__gt=datetime.datetime.now() - datetime.timedelta(1))\nby_kw(conn, Person, created__gte=datetime.datetime.now() - datetime.timedelta(1))\n\n\n# Get an object by Primary Key\nby_pk(conn, Person, \"4fdd6a2d-ff49-41b6-b92a-dc05beb67298\")\nby_pk(conn, Person, \"4fdd6a2d-ff49-41b6-b92a-dc05beb67298\")\n\n# Updating\nby_kw(conn, Person, username=\"my_username\").kw_update(email=\"new_email@example.com\")\nquery(conn, Person).kw_update(email=\"some@example.com\", active=True)\nsave(conn, exising_person)\n# Update with a function, lets you use fields.\ndef set_fn(person):\nperson.email = person.verification().email\nperson.active = True\n\ndef where_fn(person):\nreturn is_not_null(person.verification().completed)\n\nquery(conn, Person).where(where_fn).update(set_fn)\nupdate(conn, Person, set_fn, where_fn)\n\n\n# Deleting\nquery(conn, Person).kw_where(username=\"my_username\").delete()\nquery(conn, Person).where(lambda x: x.username == \"my_username\").delete()\ndelete(conn, Person, lambda x: x.username == \"my_username\")\n\n# Insert an object\nsave(conn, Person(email=\"user@example.com\"))\n# Insert many objects\ninsert_objs(conn, Person, [Person(email=\"user@example.com\"), Person(email=\"user2@example.com\")])\n\n# Reload an object from the db\nreload(conn, existing_person)\n\n# limit results\nquery(conn, Person).limit(1)\n# Order\nquery(conn, Person).order_by(lambda x: x.updated)\nquery(conn, Person).order_by(lambda x: Desc(x.updated)) # Descend\nquery(conn, Person).order_by(lambda x: (Asc(x.birthday), Desc(x.updated))) # Mix and match\nquery(conn, Person).order_by(lambda x: x.updated).limit(1)\n\n# Prepare a result set to indicate that only one row will be returned.\nupdate(conn, Person, do, where) # will return a list when `execute` is called\nupdate(conn, Person, do, where, one=True)  # will return one or None rows when `execute` is called\nquery(conn, Person) # will return a list when `resolve` is called\nquery(conn, Person, one=True) # will return one or None rows when `resolve` is called","executing-queries#Executing Queries":"To run the queries on Postgres, we need to call their appropriate method.\nfrom rhubarb.crud import query, save, insert_objs\n\n# Executing Object sets\nawait query(conn, Person).one() # return the result (one or none)\nawait query(conn, Person).as_list() # return the result (list)\nawait query(conn, Person, one=one_or_many).resolve() # return the result (dependent on `one` kwarg passed to query)\n\n# Executing Mutations\nawait insert_objs(conn, Person, ...).execute() # Execute and return list\nawait insert_objs(conn, Person, ...).execute(one=True) # Execute and return first object\nawait save(conn, Person(...)).execute() # Execute and return one object\nawait query(conn, Person).update(...).execute() # Execute and return list\nawait query(conn, Person, one=True).update(...).execute() # Execute and return one or none objects\nawait query(conn, Person, one=True).delete().execute() # Execute and return one or none objects\nawait query(conn, Person).update(...).execute(one=True) # Execute and return one or none objects","objectset-and-cached-results#ObjectSet and Cached Results":"An ObjectSet will cache results once as_list / resolve / one is called.\nq = query(conn, Person) # No query performed\nl: list[Person] = q.as_list() # Query performed the first time.\nl: list[Person] = q.as_list() # No query performed the second time.\np: Optional[Person] = q.by_pk(\"123\") # No query performed, get specific object from its cache.","find-or-create#Find or Create":"Attempt to find the record by kw, if not, insert the object.\nfrom rhubarb.crud import find_or_create\n\nobj = await find_or_create(conn, Person(email=\"user@example.com\"), email=\"user@example.com\")","counting--exists#Counting / Exists":"Count the rows or tell if any rows exists. These will do new queries and do not cache results.\nawait query(conn, Person).count() # Executes a COUNT(*) and returns an int\nawait query(conn, Person).exists() # Executes a SELECT TRUE LIMIT 1 and returns an bool"}},"/":{"title":"Rhubarb - The Funky Sweet Python Framework Built With Strawberry GraphQL","data":{"":"Rhubarb is an ORM baked from scratch focused on automatic optimizations with Postgres data using GQL.\n\n\n\nStrawberry-Rhubarb Pie... Tasty!","rhubarb-at-a-glance#Rhubarb at a glance":"Asyncio Native\nBuild SQL Queries with Python\nBuilt on GraphQL for optimization layer on nested queries\nMigrations - Automatically generate Schema changes as your data model updates.\nIntuitively Solve N+1 without even realizing it\nSimplify Aggregations / Joins / Subqueries\nHeavily inspired by Django and built with the philosophy of take the best parts.\nNative Public / Private Schema dichotomy\nPass User and Extra info to use in queries through Strawberry Info's context.\nDoesn't use any other Python ORM for DB access, only Psycopg3","extra-rhubarb-features#Extra Rhubarb Features":"Rhubarb comes with some extra integrations to make using the ORM easy...\nHTTP - FastAPI / Starlette\nRedis - Rate Limiting / Caching\nAuth - Impersonate / Sessions / Users / WebAuthN / Password\nSecurity - CORS / CSRF / Field Level Security / Auth Rate Limits\nAuditing - Record all Mutations / Queries / Subscriptions / Custom Events\nTasks Queue - Chron and one off tasks offloaded to worker processes using arq.","automatic-sql-optimizations#Automatic SQL Optimizations":"Currently, Rhubarb does a few optimizations that cover most uses:\nSelecting only the columns being asked for in the current GQL query\nInlining joins that don't produce more rows.\nManaging exploding cartesian products from m:n joins\nPushing Aggregates to Subquery\nCombining aggregates if they use same GROUP BY","package-status#Package Status":"This is an experimental package for researching new ways in Python to interact with Postgres and build apps. Take care.","researched-by-getdynasty#Researched by GetDynasty":"This package was created with the help of research resources provided by Dynasty Living Trusts. GetDynasty is the only online platform that offers instant Living Trust Creation. GetDynasty is not actively involved in the maintenance or development of this project."}},"/tables/base_models":{"title":"Base Models","data":{"":"There are some convenience superclasses that will add primary keys and utility fields to your Model automatically.\nBaseModel - UUID Primary Key\nBaseUpdateAtModel - UUID Primary Key, created, updated fields.\nBaseIntModel - SERIAL Primary Key\nBaseIntUpdateAtModel - SERIAL Primary Key, created, updated fields."}},"/tables/custom_types":{"title":"Built-in Column / Sql Types","data":{"":"You can create your own Postgres Type by using Strawberry custom scalars. The scalars base type must already be a built in type (see the example of rhubarb.core.Email) or wrap a new type.serializeIf you want to have a new type that isn't a builtin, you must implement __sql_type__ and __sql__.","example#Example":"In this example, we use the JSONB Postgres type to store a custom dataclass:\nfrom typing import NewType\nimport dataclasses\nfrom rhubarb import SqlType, SqlBuilder\nfrom strawberry import scalar\n\n\njson_sql_type = SqlType.from_python(dict)\n\n\n@dataclasses.dataclass\nclass MyCustomType:\na: int\nb: str\no: list[int]\n\n@staticmethod\ndef __sql_type__():\nreturn json_sql_type\n\ndef __sql__(self, builder: SqlBuilder):\nbuilder.write_value(self.serialize(), json_sql_type)\n\ndef serialize(self):\nreturn dataclasses.asdict(self)\n\n\nCustomType = scalar(\nNewType(\"CustomType\", MyCustomType),\nserialize=lambda v: v.serialize(),\nparse_value=lambda v: MyCustomType(**v),\n)"}},"/tables/migrations":{"title":"Migrations","data":{"":"Rhubarb has basic support for migrations. It will watch for new, changed columns and tables.","migration-commands#Migration Commands":"Make migrations with:\npython -m rhubarb.migrations.cmd.make\nApply migrations with\npython -m rhubarb.migrations.cmd.apply\nDrop all Tables\npython -m rhubarb.migrations.cmd.reset","migration-basics#Migration Basics":"You can manage migrations with Registries. A registry is a group of models that can include other registries. This allows you include apps with collections of models in your app.By default there is a DEFAULT_REGISTRY that all models will be associated with unless otherwise specified. In general if you are creating your models that will run as your main app, you can use DEFAULT_REGISTRY, but the options are there to customize. If you do want to use a different registry as your main registry of your app, set Config.registry\nfrom rhubarb import DEFAULT_REGISTRY, Registry, BaseModel, table\n\n# You can link other registries to your registry, this is useful for other plugins or libs.\nDEFAULT_REGISTRY.link(third_party_registry)\n\n\n# Go to default registry\n@table\nclass SomeTable(BaseModel):\npass\n\n# Go to your specific registry\n@table(registry=registry)\nclass MyTable(BaseModel):\npass\n\n\n# Don't include in migrations...\n@table(skip_registry=True)\nclass OtherTable(BaseModel):\npass","indexes-and-constraints#Indexes and Constraints":"Indexes and constraints are returned with the __indexes__ and __constraints__ function. Rhubarb will monitor if these change by their key and generate migrations if needed.\nfrom rhubarb import BaseModel, column, table, Index, Constraint\nfrom rhubarb.functions import concat\n\n\n@table\nclass Person(BaseModel):\nfirst_name: str = column()\nlast_name: str = column()\nfavorite_number: int = column()\nleast_favorite_number: int = column()\n\ndef __indexes__(self):\nreturn {\n\"by_last_name_comma_first\": Index(\non=concat(self.last_name, \",\", self.first_name)\n),\n\"by_favorite_number\": Index(\non=self.favorite_number\n)\n}\n\ndef __constraints__(self):\nreturn {\n\"favorite_ne_least_favorite\": Constraint(\ncheck=self.favorite_number != self.least_favorite_number\n)\n}\nYou can add a DEFAULT to a column with sql_default. Only some SQL functions are supported in order to preserve serialization functionality with Migrations for now.\nimport uuid\nimport datetime\nfrom rhubarb import BaseModel, column, table, BUILTINS\n\n\n@table\nclass AwesomeTable(BaseModel):\nsome_uuid: uuid.UUID = column(sql_default=BUILTINS.UUID_GENERATE_V4)\nsome_datetime: datetime.datetime = column(sql_default=BUILTINS.NOW)","running-python-in-migrations#Running Python in Migrations":"If you want to run a data migration and you need to run python, then generate migrations with --empty, and add  RunPython to the operations list.\npython -m rhubarb.migrations.cmd.make --empty\nWith RunPython, you get a snapshot of table instances with only concrete fields (no virtual columns or relationships). If you need a computation, redefine it inside the migration so that when you code changes, your migration will always stay the same.\nfrom rhubarb import migrations\nfrom rhubarb import query, save, table, virtual_column, relation, update\n\n\nasync def mig_fn(info: migrations.MigrationInfo):\nRatingModel = info.get_model(\"ratingmodel\")\nReviewerModel = info.get_model(\"reviewermodel\")\n\n# manually iterate, or just use normal CRUD functions...\nobjs = await query(info.conn, RatingModel).as_list()\nfor obj in objs:\nobj.rating += 10\nawait save(info.conn, obj).execute()\n\n# Also, you can create virtual models and use their fields.\n# Because they are defined inside the migration, they are safe from changes in the app.\n@table(skip_registry=True)\nclass MigRatingModel(RatingModel):\n@virtual_column\ndef inflated(self) -> int:\nreturn self.rating + 10\n\n@relation\ndef reviewer(self, reviewer: ReviewerModel):\nreturn self.reviewer_id == reviewer.id\n\n# Do an update using the fields and relations\ndef set_fn(m):\nm.rating = m.inflated()\n\ndef where_fn(m):\nreturn m.reviewer().email == \"some@example.com\"\n\nawait update(info.conn, MigRatingModel, set_fn, where_fn).execute()\n\n\n\ndef migrate():\nreturn migrations.Migration(\nid=\"migration_20230426-034718\",\ndepends_on=[...],\noperations=[\nmigrations.RunPython(mig_fn)\n]\n)"}},"/tables/public-private-schemas":{"title":"Supporting Public and Private Schemas","data":{"":"While you can expose your Schema on FastAPI directly, and that may be beneficial for internal use, but for the public users, you do not want all your DB Columns exposed.Simply create a new schema using standard type and field exposing only the fields you want from the underlying object exposed.For example if we use the table basics example that has a lot of fields, we can create another schema that will be served to the public based on the more complicated private schema.\nimport rhubarb\nfrom rhubarb import Schema, ObjectSet, RhubarbExtension, get_conn, query\nfrom strawberry.types import Info\nfrom strawberry.scalars import Base64\n\n\n@rhubarb.type\nclass TableWithoutSuperClass:\ninfo: str\n\n\n\n@rhubarb.type\nclass PublicPerson:\nname: str\n# If you are exposing public APIs, better to serialize the Binary fields as Base64\nexample_bytes_col: Base64\n\n@rhubarb.field\ndef other_table(self) -> TableWithoutSuperClass:\nreturn self.other_table()\n\n@rhubarb.field\ndef int_is_big(self) -> bool:\nreturn self.int_is_big()\n\n\n@rhubarb.type\nclass PublicQuery:\n# Do the query on the Private type and return an ObjectSet, but make the GQL type a Public type instead.\n@rhubarb.field(graphql_type=list[PublicPerson])\ndef public_people(self, info: Info) -> ObjectSet[Person, Person]:\nreturn query(get_conn(info), Person, info).where(lambda x: x.example_int_col > 10)\n\n\npublic_schema = Schema(\nquery=PublicQuery,\nextensions=[\nRhubarbExtension\n]\n)"}},"/tables/table_basics":{"title":"Creating Tables","data":{"":"Tables are mapped from Postgres to Python through Strawberry datatypes. Each column that is in your DB can be loaded into the datatype through the column() field type.The following special class attributes are used to define the table's relation to Postgres\nPython\tPostgres\t__schema__\tWhat schema to use that contains the model\t__table__\tPostgres Table Name\t__pks__\twhat field or tuple of fields to use for primary key\n\nimport decimal\nimport datetime\nimport uuid\nfrom typing import Optional\nfrom rhubarb import Schema, ObjectSet, ModelSelector, BaseModel, column, table, type, \\\nfield, get_conn, query, references, relation, virtual_column, Binary\nfrom strawberry.scalars import JSON\nfrom strawberry.types import Info\n\n\n@table\nclass TableWithoutSuperClass:\n__schema__ = \"public\"\n__table__ = \"my_awesome_table\"\n__pks__ = \"id\"\nid: int = column()\ninfo: str = column()\n\n\n\n@table\nclass Person(BaseModel):\nname: str = column()\nsome_uuid: Optional[uuid.UUID] = column(sql_default=\"generate_uuid_v4()\")\na_bool_column: bool = column(column_name=\"awesome_custom_column_name\")\nexample_dt_col: datetime.datetime = column(sql_default=\"now()\")\nexample_date_col: datetime.date = column()\nexample_float_col: float = column()\nexample_int_col: int = column()\nexample_decimal_col: decimal.Decimal = column()\nexample_bytes_col: Binary = column()\nexample_jsonb_col: JSON = column()\n\nother_table_reference_id: int = references(TableWithoutSuperClass.__table__)\n\n@relation\ndef other_table(self, other: TableWithoutSuperClass):\nreturn self.other_table_reference_id == other.id\n\n@virtual_column\ndef int_is_big(self) -> bool:\nreturn self.example_int_col > 100\n\n@type\nclass Query:\n@field(graphql_type=list[Person])\ndef all_people(self, info: Info) -> ObjectSet[Person, Person]:\nreturn query(get_conn(info), Person, info)\n\n\nschema = Schema(\nquery=Query\n)"}},"/tables/types":{"title":"Built-in Column / Sql Types","data":{"":"When creating tables, refer to this Guide about the mappings between Python Type and Postgres Type\nPython\tPostgres\tNotes\tbool\tBOOLEAN\t\tint\tBIGINT\t\tfloat\tFLOAT\t\tdecimal.Decimal\tDECIMAL\t\tstr\tTEXT\t\tbytes\tBYTEA\t\tdatetime.datetime\tTIMESTAMPTZ\t\tdatetime.date\tDATE\t\tuuid.UUID\tUUID\t\ttyping.Optional\tNull columns\t\trhubarb.PhoneNumber\tTEXT\tdecodes as phonenumbers.PhoneNumber\trhubarb.Email\tTEXT\tWraps str\tdict\tJSONB\t\tlist\tJSONB\t\tstrawberry.scalars.JSON\tJSONB\t\tstrawberry.scalars.Base64\tBYTEA\tdecodes as str\tstrawberry.scalars.Base32\tBYTEA\tdecodes as str\tstrawberry.scalars.Base16\tBYTEA\tdecodes as str\trhubarb.SmallInt\tSMALLINT\t\trhubarb.core.Binary\tBYTEA\tdecodes as bytes\trhubarb.core.Serial\tSERIAL\t\tNone\tNULL\tcannot use as column type, only value"}}}